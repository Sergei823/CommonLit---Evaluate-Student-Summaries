{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Testing the model on a target of two variables. Cross validation on folds by prompts_id. Saving the best models for later averaging.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom transformers import AutoConfig, AutoTokenizer, AutoModel\n#from transformers import DebertaTokenizer, DebertaModel\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom argparse import Namespace\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import LeaveOneGroupOut\n\nfrom tqdm import tqdm as tq\nfrom tqdm import notebook","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:23.730358Z","iopub.execute_input":"2023-10-05T12:04:23.730668Z","iopub.status.idle":"2023-10-05T12:04:29.705142Z","shell.execute_reply.started":"2023-10-05T12:04:23.730642Z","shell.execute_reply":"2023-10-05T12:04:29.704214Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nseed = 123\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\nnp.random.seed(seed)\nrandom.seed(seed)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-10-05T12:04:29.707017Z","iopub.execute_input":"2023-10-05T12:04:29.707566Z","iopub.status.idle":"2023-10-05T12:04:29.716537Z","shell.execute_reply.started":"2023-10-05T12:04:29.707534Z","shell.execute_reply":"2023-10-05T12:04:29.715583Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"sum_train=pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\nsum_train","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:29.717885Z","iopub.execute_input":"2023-10-05T12:04:29.718797Z","iopub.status.idle":"2023-10-05T12:04:29.828858Z","shell.execute_reply.started":"2023-10-05T12:04:29.718727Z","shell.execute_reply":"2023-10-05T12:04:29.827931Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        student_id prompt_id  \\\n0     000e8c3c7ddb    814d6b   \n1     0020ae56ffbf    ebad26   \n2     004e978e639e    3b9047   \n3     005ab0199905    3b9047   \n4     0070c9e7af47    814d6b   \n...            ...       ...   \n7160  ff7c7e70df07    ebad26   \n7161  ffc34d056498    3b9047   \n7162  ffd1576d2e1b    3b9047   \n7163  ffe4a98093b2    39c16e   \n7164  fffbccfd8a08    ebad26   \n\n                                                   text   content   wording  \n0     The third wave was an experimentto see how peo...  0.205683  0.380538  \n1     They would rub it up with soda to make the sme... -0.548304  0.506755  \n2     In Egypt, there were many occupations and soci...  3.128928  4.231226  \n3     The highest class was Pharaohs these people we... -0.210614 -0.471415  \n4     The Third Wave developed  rapidly because the ...  3.272894  3.219757  \n...                                                 ...       ...       ...  \n7160  They used all sorts of chemical concoctions to...  0.205683  0.380538  \n7161  The lowest classes are slaves and farmers slav... -0.308448  0.048171  \n7162             they sorta made people start workin... -1.408180 -0.493603  \n7163  An ideal tragety has three elements that make ... -0.393310  0.627128  \n7164  The meat would smell sour but the would \"rub i...  1.771596  0.547742  \n\n[7165 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000e8c3c7ddb</td>\n      <td>814d6b</td>\n      <td>The third wave was an experimentto see how peo...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0020ae56ffbf</td>\n      <td>ebad26</td>\n      <td>They would rub it up with soda to make the sme...</td>\n      <td>-0.548304</td>\n      <td>0.506755</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004e978e639e</td>\n      <td>3b9047</td>\n      <td>In Egypt, there were many occupations and soci...</td>\n      <td>3.128928</td>\n      <td>4.231226</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>005ab0199905</td>\n      <td>3b9047</td>\n      <td>The highest class was Pharaohs these people we...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0070c9e7af47</td>\n      <td>814d6b</td>\n      <td>The Third Wave developed  rapidly because the ...</td>\n      <td>3.272894</td>\n      <td>3.219757</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7160</th>\n      <td>ff7c7e70df07</td>\n      <td>ebad26</td>\n      <td>They used all sorts of chemical concoctions to...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n    </tr>\n    <tr>\n      <th>7161</th>\n      <td>ffc34d056498</td>\n      <td>3b9047</td>\n      <td>The lowest classes are slaves and farmers slav...</td>\n      <td>-0.308448</td>\n      <td>0.048171</td>\n    </tr>\n    <tr>\n      <th>7162</th>\n      <td>ffd1576d2e1b</td>\n      <td>3b9047</td>\n      <td>they sorta made people start workin...</td>\n      <td>-1.408180</td>\n      <td>-0.493603</td>\n    </tr>\n    <tr>\n      <th>7163</th>\n      <td>ffe4a98093b2</td>\n      <td>39c16e</td>\n      <td>An ideal tragety has three elements that make ...</td>\n      <td>-0.393310</td>\n      <td>0.627128</td>\n    </tr>\n    <tr>\n      <th>7164</th>\n      <td>fffbccfd8a08</td>\n      <td>ebad26</td>\n      <td>The meat would smell sour but the would \"rub i...</td>\n      <td>1.771596</td>\n      <td>0.547742</td>\n    </tr>\n  </tbody>\n</table>\n<p>7165 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sum_train.prompt_id.nunique()","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:29.831687Z","iopub.execute_input":"2023-10-05T12:04:29.832101Z","iopub.status.idle":"2023-10-05T12:04:29.842396Z","shell.execute_reply.started":"2023-10-05T12:04:29.832056Z","shell.execute_reply":"2023-10-05T12:04:29.841264Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"code","source":"#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n#tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\ntokenizer =AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\nsep=tokenizer.sep_token","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:29.843634Z","iopub.execute_input":"2023-10-05T12:04:29.844518Z","iopub.status.idle":"2023-10-05T12:04:31.728198Z","shell.execute_reply.started":"2023-10-05T12:04:29.844488Z","shell.execute_reply":"2023-10-05T12:04:31.727267Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e664fffbb3174edd8eb880dbb3dd9943"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"064b76fa8c5a48ecb916c83d17b868e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49b15f943a2d41aebb844caa384b0e06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a69d48b35b64207af46c5c31846a48a"}},"metadata":{}}]},{"cell_type":"code","source":"import pickle\nwith open(\"bert_tokenizer.pkl\", \"wb\") as f:\n    pickle.dump(tokenizer, f)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:31.729489Z","iopub.execute_input":"2023-10-05T12:04:31.730448Z","iopub.status.idle":"2023-10-05T12:04:31.763407Z","shell.execute_reply.started":"2023-10-05T12:04:31.730411Z","shell.execute_reply":"2023-10-05T12:04:31.762540Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tkn=tokenizer.tokenize('Hello, student 2023!')\ntkn","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:31.764678Z","iopub.execute_input":"2023-10-05T12:04:31.765581Z","iopub.status.idle":"2023-10-05T12:04:31.782697Z","shell.execute_reply.started":"2023-10-05T12:04:31.765549Z","shell.execute_reply":"2023-10-05T12:04:31.782033Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['Hello', ',', 'Ġstudent', 'Ġ20', '23', '!']"},"metadata":{}}]},{"cell_type":"code","source":"sum_train['len_text']=sum_train.text.apply(lambda x: len(tokenizer.tokenize(x)))\nmax_len=sum_train.len_text.max()\nq_97=sum_train.len_text.quantile(q=0.97)\nsum_train.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:31.783901Z","iopub.execute_input":"2023-10-05T12:04:31.784441Z","iopub.status.idle":"2023-10-05T12:04:33.770780Z","shell.execute_reply.started":"2023-10-05T12:04:31.784410Z","shell.execute_reply":"2023-10-05T12:04:33.769880Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"     student_id prompt_id                                               text  \\\n0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n\n    content   wording  len_text  \n0  0.205683  0.380538        69  \n1 -0.548304  0.506755        56  \n2  3.128928  4.231226       291  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>len_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000e8c3c7ddb</td>\n      <td>814d6b</td>\n      <td>The third wave was an experimentto see how peo...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0020ae56ffbf</td>\n      <td>ebad26</td>\n      <td>They would rub it up with soda to make the sme...</td>\n      <td>-0.548304</td>\n      <td>0.506755</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004e978e639e</td>\n      <td>3b9047</td>\n      <td>In Egypt, there were many occupations and soci...</td>\n      <td>3.128928</td>\n      <td>4.231226</td>\n      <td>291</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"max_len, q_97","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:33.772332Z","iopub.execute_input":"2023-10-05T12:04:33.772666Z","iopub.status.idle":"2023-10-05T12:04:33.778613Z","shell.execute_reply.started":"2023-10-05T12:04:33.772634Z","shell.execute_reply":"2023-10-05T12:04:33.777685Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(843, 259.0799999999999)"},"metadata":{}}]},{"cell_type":"code","source":"prompts_train=pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\nprompts_train['prompt_text_token']=prompts_train.prompt_text.apply(lambda x: tokenizer.tokenize(x)[:1200])\nprompts_train['prompt_text_ids']=prompts_train.prompt_text_token.apply(lambda x: [1]+tokenizer.convert_tokens_to_ids(x)+[2])\n#prompts_train['prompt_q_token']=prompts_train.prompt_question.apply(lambda x: tokenizer.tokenize(x)[:1200])\n#prompts_train['prompt_q_ids']=prompts_train.prompt_q_token.apply(lambda x: [1]+tokenizer.convert_tokens_to_ids(x)+[2])\nprompts_train","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:33.783707Z","iopub.execute_input":"2023-10-05T12:04:33.784306Z","iopub.status.idle":"2023-10-05T12:04:33.819026Z","shell.execute_reply.started":"2023-10-05T12:04:33.784229Z","shell.execute_reply":"2023-10-05T12:04:33.818170Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"  prompt_id                                    prompt_question  \\\n0    39c16e  Summarize at least 3 elements of an ideal trag...   \n1    3b9047  In complete sentences, summarize the structure...   \n2    814d6b  Summarize how the Third Wave developed over su...   \n3    ebad26  Summarize the various ways the factory would u...   \n\n                prompt_title  \\\n0                 On Tragedy   \n1  Egyptian Social Structure   \n2             The Third Wave   \n3    Excerpt from The Jungle   \n\n                                         prompt_text  \\\n0  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n1  Egyptian society was structured like a pyramid...   \n2  Background \\r\\nThe Third Wave experiment took ...   \n3  With one member trimming beef in a cannery, an...   \n\n                                   prompt_text_token  \\\n0  [Chapter, Ġ13, Ġ, č, Ċ, As, Ġthe, Ġsequel, Ġto...   \n1  [Egypt, ian, Ġsociety, Ġwas, Ġstructured, Ġlik...   \n2  [Background, Ġ, č, Ċ, The, ĠThird, ĠWave, Ġexp...   \n3  [With, Ġone, Ġmember, Ġtrim, ming, Ġbeef, Ġin,...   \n\n                                     prompt_text_ids  \n0  [1, 45642, 508, 1437, 50121, 50118, 1620, 5, 1...  \n1  [1, 37552, 811, 2313, 21, 16697, 101, 10, 3334...  \n2  [1, 48277, 1437, 50121, 50118, 133, 7470, 2118...  \n3  [1, 3908, 65, 919, 10723, 7059, 6829, 11, 10, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>prompt_text_token</th>\n      <th>prompt_text_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>[Chapter, Ġ13, Ġ, č, Ċ, As, Ġthe, Ġsequel, Ġto...</td>\n      <td>[1, 45642, 508, 1437, 50121, 50118, 1620, 5, 1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3b9047</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n      <td>[Egypt, ian, Ġsociety, Ġwas, Ġstructured, Ġlik...</td>\n      <td>[1, 37552, 811, 2313, 21, 16697, 101, 10, 3334...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>814d6b</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n      <td>[Background, Ġ, č, Ċ, The, ĠThird, ĠWave, Ġexp...</td>\n      <td>[1, 48277, 1437, 50121, 50118, 133, 7470, 2118...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ebad26</td>\n      <td>Summarize the various ways the factory would u...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>With one member trimming beef in a cannery, an...</td>\n      <td>[With, Ġone, Ġmember, Ġtrim, ming, Ġbeef, Ġin,...</td>\n      <td>[1, 3908, 65, 919, 10723, 7059, 6829, 11, 10, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"prompts_train['len_prompt']=prompts_train.prompt_text.apply(lambda x: len(tokenizer.tokenize(x)))\nprompts_train.len_prompt.max(), prompts_train.len_prompt.min()","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:33.820355Z","iopub.execute_input":"2023-10-05T12:04:33.820645Z","iopub.status.idle":"2023-10-05T12:04:33.839283Z","shell.execute_reply.started":"2023-10-05T12:04:33.820617Z","shell.execute_reply":"2023-10-05T12:04:33.838309Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(1199, 700)"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's create embeddings for each of the topic descriptions. To do this, let's average the penultimate layer of each token. https://russianblogs.com/article/60231465736/","metadata":{}},{"cell_type":"code","source":"#model=BertModel.from_pretrained('bert-base-uncased')\n#model=RobertaModel.from_pretrained(\"roberta-base\")\n#model = AutoModel.from_pretrained(\"microsoft/deberta-v3-base\")\nmodel = AutoModel.from_pretrained(\"microsoft/deberta-base\")\n#model_seq=DebertaForSequenceClassification.from_pretrained(\"microsoft/deberta-base\", \\\n                                                           #num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:33.840585Z","iopub.execute_input":"2023-10-05T12:04:33.841639Z","iopub.status.idle":"2023-10-05T12:04:44.705977Z","shell.execute_reply.started":"2023-10-05T12:04:33.841609Z","shell.execute_reply":"2023-10-05T12:04:44.704853Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/559M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ea47188939405ea5c6c92a64791e7c"}},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:44.707201Z","iopub.execute_input":"2023-10-05T12:04:44.707517Z","iopub.status.idle":"2023-10-05T12:04:44.717130Z","shell.execute_reply.started":"2023-10-05T12:04:44.707485Z","shell.execute_reply":"2023-10-05T12:04:44.716238Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DebertaModel(\n  (embeddings): DebertaEmbeddings(\n    (word_embeddings): Embedding(50265, 768, padding_idx=0)\n    (LayerNorm): DebertaLayerNorm()\n    (dropout): StableDropout()\n  )\n  (encoder): DebertaEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x DebertaLayer(\n        (attention): DebertaAttention(\n          (self): DisentangledSelfAttention(\n            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n            (pos_dropout): StableDropout()\n            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): StableDropout()\n          )\n          (output): DebertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): StableDropout()\n          )\n        )\n        (intermediate): DebertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): DebertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): DebertaLayerNorm()\n          (dropout): StableDropout()\n        )\n      )\n    )\n    (rel_embeddings): Embedding(1024, 768)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"with open(\"deberta_model.pkl\", \"wb\") as f:\n    pickle.dump(model, f)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:44.718593Z","iopub.execute_input":"2023-10-05T12:04:44.719266Z","iopub.status.idle":"2023-10-05T12:04:45.653485Z","shell.execute_reply.started":"2023-10-05T12:04:44.719226Z","shell.execute_reply":"2023-10-05T12:04:45.652517Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def make_sentence(x):\n    #model.eval()\n    model.eval\n    text=torch.LongTensor(x).unsqueeze(dim=0)\n    with torch.no_grad():\n        #enc_layer, _=model(text)\n        last_layer=model(text).last_hidden_state\n        #poll_out=model(text).pooler_output\n    #return torch.mean(enc_layer[11], 1).squeeze(dim=0)\n    #return(poll_out.squeeze(dim=0))\n    return torch.mean(last_layer, 1).squeeze(dim=0)\n        #return model_seq(text).logits.squeeze()","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:45.658858Z","iopub.execute_input":"2023-10-05T12:04:45.661006Z","iopub.status.idle":"2023-10-05T12:04:45.668204Z","shell.execute_reply.started":"2023-10-05T12:04:45.660973Z","shell.execute_reply":"2023-10-05T12:04:45.667416Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"prompts_train['prompt_text_sent']=prompts_train['prompt_text_ids'].apply(make_sentence)\n#prompts_train['prompt_q_sent']=prompts_train['prompt_q_ids'].apply(make_sentence)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:04:45.672404Z","iopub.execute_input":"2023-10-05T12:04:45.674904Z","iopub.status.idle":"2023-10-05T12:05:06.635628Z","shell.execute_reply.started":"2023-10-05T12:04:45.674870Z","shell.execute_reply":"2023-10-05T12:05:06.634594Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_content=pd.merge(sum_train, prompts_train, how='left', left_on='prompt_id', right_on='prompt_id')\ntrain_content.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:06.636956Z","iopub.execute_input":"2023-10-05T12:05:06.637310Z","iopub.status.idle":"2023-10-05T12:05:06.663224Z","shell.execute_reply.started":"2023-10-05T12:05:06.637273Z","shell.execute_reply":"2023-10-05T12:05:06.662228Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"student_id           0\nprompt_id            0\ntext                 0\ncontent              0\nwording              0\nlen_text             0\nprompt_question      0\nprompt_title         0\nprompt_text          0\nprompt_text_token    0\nprompt_text_ids      0\nlen_prompt           0\nprompt_text_sent     0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train_content['len_ratio']=train_content.len_text/train_content.len_prompt","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:06.664649Z","iopub.execute_input":"2023-10-05T12:05:06.665306Z","iopub.status.idle":"2023-10-05T12:05:06.670964Z","shell.execute_reply.started":"2023-10-05T12:05:06.665276Z","shell.execute_reply":"2023-10-05T12:05:06.670020Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_c=train_content.drop(['prompt_text', 'prompt_title','prompt_question', 'prompt_text_ids',\\\n                           'prompt_text_token', 'len_text', 'len_prompt'], axis=1)\ntrain_c.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:06.672448Z","iopub.execute_input":"2023-10-05T12:05:06.673049Z","iopub.status.idle":"2023-10-05T12:05:06.799334Z","shell.execute_reply.started":"2023-10-05T12:05:06.673015Z","shell.execute_reply":"2023-10-05T12:05:06.798392Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"     student_id prompt_id                                               text  \\\n0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n\n    content   wording                                   prompt_text_sent  \\\n0  0.205683  0.380538  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   \n1 -0.548304  0.506755  [tensor(-0.6038), tensor(0.0009), tensor(-0.00...   \n2  3.128928  4.231226  [tensor(0.0025), tensor(0.3075), tensor(-0.016...   \n\n   len_ratio  \n0   0.098571  \n1   0.046706  \n2   0.392713  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>prompt_text_sent</th>\n      <th>len_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000e8c3c7ddb</td>\n      <td>814d6b</td>\n      <td>The third wave was an experimentto see how peo...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n      <td>0.098571</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0020ae56ffbf</td>\n      <td>ebad26</td>\n      <td>They would rub it up with soda to make the sme...</td>\n      <td>-0.548304</td>\n      <td>0.506755</td>\n      <td>[tensor(-0.6038), tensor(0.0009), tensor(-0.00...</td>\n      <td>0.046706</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004e978e639e</td>\n      <td>3b9047</td>\n      <td>In Egypt, there were many occupations and soci...</td>\n      <td>3.128928</td>\n      <td>4.231226</td>\n      <td>[tensor(0.0025), tensor(0.3075), tensor(-0.016...</td>\n      <td>0.392713</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"SPLIT_SEED=92\nfrom sklearn.model_selection import train_test_split\n\n#data_train, data_val = train_test_split(train_c, test_size=0.20, random_state=SPLIT_SEED)\nprompt_list=list(prompts_train['prompt_id'])\ndata_train=train_c[(train_c.prompt_id==prompt_list[0]) | (train_c.prompt_id==prompt_list[1]) |\\\n                   (train_c.prompt_id==prompt_list[3])].copy()\n\ndata_val=train_c[(train_c.prompt_id==prompt_list[2])].copy()\n                   \ndata_train['split']='train'\ndata_val['split']='val'\ndata_with_split=pd.concat([data_train, data_val], ignore_index=True)\ndata_with_split","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:06.800789Z","iopub.execute_input":"2023-10-05T12:05:06.801341Z","iopub.status.idle":"2023-10-05T12:05:07.175525Z","shell.execute_reply.started":"2023-10-05T12:05:06.801308Z","shell.execute_reply":"2023-10-05T12:05:07.174597Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"        student_id prompt_id  \\\n0     0020ae56ffbf    ebad26   \n1     004e978e639e    3b9047   \n2     005ab0199905    3b9047   \n3     0071d51dab6d    ebad26   \n4     0072b649a88c    3b9047   \n...            ...       ...   \n7160  fe1e3c528e24    814d6b   \n7161  fe6fac61dc49    814d6b   \n7162  fed33a5f383e    814d6b   \n7163  fefd4f143fbe    814d6b   \n7164  ff5b8d659ca6    814d6b   \n\n                                                   text   content   wording  \\\n0     They would rub it up with soda to make the sme... -0.548304  0.506755   \n1     In Egypt, there were many occupations and soci...  3.128928  4.231226   \n2     The highest class was Pharaohs these people we... -0.210614 -0.471415   \n3     They would use chemicals and substances to cha...  0.205683  0.380538   \n4     The Egyptian society is really different from ...  0.205683  0.380538   \n...                                                 ...       ...       ...   \n7160       The third wave experiment developed quick...  3.020803  2.421200   \n7161  Mr jones started the third wave as a  expereme...  1.221089  2.269070   \n7162  The Third Wave gained over 200 members by the ...  2.141224  1.123777   \n7163  The Third Wave developed over such a short tim... -0.782641 -0.245970   \n7164  Jones created a movement, which he caled \"The ...  2.049876  1.673049   \n\n                                       prompt_text_sent  len_ratio  split  \n0     [tensor(-0.6038), tensor(0.0009), tensor(-0.00...   0.046706  train  \n1     [tensor(0.0025), tensor(0.3075), tensor(-0.016...   0.392713  train  \n2     [tensor(0.0025), tensor(0.3075), tensor(-0.016...   0.053981  train  \n3     [tensor(-0.6038), tensor(0.0009), tensor(-0.00...   0.039199  train  \n4     [tensor(0.0025), tensor(0.3075), tensor(-0.016...   0.121457  train  \n...                                                 ...        ...    ...  \n7160  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   0.252857    val  \n7161  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   0.120000    val  \n7162  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   0.238571    val  \n7163  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   0.044286    val  \n7164  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   0.241429    val  \n\n[7165 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>prompt_text_sent</th>\n      <th>len_ratio</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0020ae56ffbf</td>\n      <td>ebad26</td>\n      <td>They would rub it up with soda to make the sme...</td>\n      <td>-0.548304</td>\n      <td>0.506755</td>\n      <td>[tensor(-0.6038), tensor(0.0009), tensor(-0.00...</td>\n      <td>0.046706</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>004e978e639e</td>\n      <td>3b9047</td>\n      <td>In Egypt, there were many occupations and soci...</td>\n      <td>3.128928</td>\n      <td>4.231226</td>\n      <td>[tensor(0.0025), tensor(0.3075), tensor(-0.016...</td>\n      <td>0.392713</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>005ab0199905</td>\n      <td>3b9047</td>\n      <td>The highest class was Pharaohs these people we...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n      <td>[tensor(0.0025), tensor(0.3075), tensor(-0.016...</td>\n      <td>0.053981</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0071d51dab6d</td>\n      <td>ebad26</td>\n      <td>They would use chemicals and substances to cha...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n      <td>[tensor(-0.6038), tensor(0.0009), tensor(-0.00...</td>\n      <td>0.039199</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0072b649a88c</td>\n      <td>3b9047</td>\n      <td>The Egyptian society is really different from ...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n      <td>[tensor(0.0025), tensor(0.3075), tensor(-0.016...</td>\n      <td>0.121457</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7160</th>\n      <td>fe1e3c528e24</td>\n      <td>814d6b</td>\n      <td>The third wave experiment developed quick...</td>\n      <td>3.020803</td>\n      <td>2.421200</td>\n      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n      <td>0.252857</td>\n      <td>val</td>\n    </tr>\n    <tr>\n      <th>7161</th>\n      <td>fe6fac61dc49</td>\n      <td>814d6b</td>\n      <td>Mr jones started the third wave as a  expereme...</td>\n      <td>1.221089</td>\n      <td>2.269070</td>\n      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n      <td>0.120000</td>\n      <td>val</td>\n    </tr>\n    <tr>\n      <th>7162</th>\n      <td>fed33a5f383e</td>\n      <td>814d6b</td>\n      <td>The Third Wave gained over 200 members by the ...</td>\n      <td>2.141224</td>\n      <td>1.123777</td>\n      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n      <td>0.238571</td>\n      <td>val</td>\n    </tr>\n    <tr>\n      <th>7163</th>\n      <td>fefd4f143fbe</td>\n      <td>814d6b</td>\n      <td>The Third Wave developed over such a short tim...</td>\n      <td>-0.782641</td>\n      <td>-0.245970</td>\n      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n      <td>0.044286</td>\n      <td>val</td>\n    </tr>\n    <tr>\n      <th>7164</th>\n      <td>ff5b8d659ca6</td>\n      <td>814d6b</td>\n      <td>Jones created a movement, which he caled \"The ...</td>\n      <td>2.049876</td>\n      <td>1.673049</td>\n      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n      <td>0.241429</td>\n      <td>val</td>\n    </tr>\n  </tbody>\n</table>\n<p>7165 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, text_df, max_seq_length):\n        \n        self.text_df = text_df \n        \n        self._max_seq_length = max_seq_length\n\n        self.train_df = self.text_df[self.text_df.split=='train']\n        self.train_size = len(self.train_df)\n\n        self.val_df = self.text_df[self.text_df.split=='val']\n        self.validation_size = len(self.val_df)\n\n        self._lookup_dict = {'train': (self.train_df, self.train_size), \n                             'val': (self.val_df, self.validation_size)}\n\n        self.set_split('train')\n       \n\n    def set_split(self, split=\"train\"):\n        self._data_split = split\n        self._data_df, self._data_size = self._lookup_dict[split]\n\n    def __len__(self):\n        return self._data_size\n\n    def __getitem__(self, index):\n        \n        row = self._data_df.iloc[index]\n        text=row['text']\n        tokens=tokenizer.tokenize(text)\n        text_index=[1]+tokenizer.convert_tokens_to_ids(tokens)+[2]        \n        token_index=text_index\n                \n        if len(token_index)<self._max_seq_length:\n            pad=[0]*(self._max_seq_length-len(token_index))\n            token_index=token_index+pad\n                      \n        else:\n            token_index=token_index[:self._max_seq_length]\n            \n        data_vector = torch.LongTensor(token_index) \n        \n        target = row[['content', 'wording']]\n        \n        return {'x_data': data_vector,\n                'attention_mask': (data_vector!=0).long(),\n                'content_vector': row['prompt_text_sent'],                \n                'y_target': torch.squeeze(torch.FloatTensor([target])),                \n                'len_ratio': row['len_ratio']}\n\n    def get_num_batches(self, batch_size):\n        \n        return len(self) // batch_size\n","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:07.176710Z","iopub.execute_input":"2023-10-05T12:05:07.177509Z","iopub.status.idle":"2023-10-05T12:05:07.187372Z","shell.execute_reply.started":"2023-10-05T12:05:07.177477Z","shell.execute_reply":"2023-10-05T12:05:07.186460Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"data=TextDataset(data_with_split, 350)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:07.188574Z","iopub.execute_input":"2023-10-05T12:05:07.189411Z","iopub.status.idle":"2023-10-05T12:05:07.207493Z","shell.execute_reply.started":"2023-10-05T12:05:07.189378Z","shell.execute_reply":"2023-10-05T12:05:07.206308Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"t=data.__getitem__(0)\n#t","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:07.212443Z","iopub.execute_input":"2023-10-05T12:05:07.212692Z","iopub.status.idle":"2023-10-05T12:05:07.220892Z","shell.execute_reply.started":"2023-10-05T12:05:07.212660Z","shell.execute_reply":"2023-10-05T12:05:07.220038Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"t['x_data'].shape, t['content_vector'].shape, t['y_target'].shape, t['attention_mask'].shape","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:07.222129Z","iopub.execute_input":"2023-10-05T12:05:07.222952Z","iopub.status.idle":"2023-10-05T12:05:07.231740Z","shell.execute_reply.started":"2023-10-05T12:05:07.222921Z","shell.execute_reply":"2023-10-05T12:05:07.230802Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(torch.Size([350]), torch.Size([768]), torch.Size([2]), torch.Size([350]))"},"metadata":{}}]},{"cell_type":"code","source":"def generate_batches(dataset, batch_size, shuffle=True,\n                     drop_last=True, device=\"cpu\"): \n    \"\"\"\n    A generator function which wraps the PyTorch DataLoader. It will \n      ensure each tensor is on the write device location.\n    \"\"\"\n    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n                            shuffle=shuffle, drop_last=drop_last)\n\n    for data_dict in dataloader:\n        out_data_dict = {}\n        for name, tensor in data_dict.items():\n            out_data_dict[name] = data_dict[name].to(device)\n            \n        yield out_data_dict","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:07.232951Z","iopub.execute_input":"2023-10-05T12:05:07.234062Z","iopub.status.idle":"2023-10-05T12:05:07.243188Z","shell.execute_reply.started":"2023-10-05T12:05:07.234033Z","shell.execute_reply":"2023-10-05T12:05:07.242246Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"gen=generate_batches(data, 3)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:07.244365Z","iopub.execute_input":"2023-10-05T12:05:07.245074Z","iopub.status.idle":"2023-10-05T12:05:07.259395Z","shell.execute_reply.started":"2023-10-05T12:05:07.245045Z","shell.execute_reply":"2023-10-05T12:05:07.258488Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"g=next(gen)\ng['x_data'].shape, g['y_target'].shape, g['len_ratio'].shape\n","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:07.260556Z","iopub.execute_input":"2023-10-05T12:05:07.261469Z","iopub.status.idle":"2023-10-05T12:05:07.282632Z","shell.execute_reply.started":"2023-10-05T12:05:07.261329Z","shell.execute_reply":"2023-10-05T12:05:07.281621Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(torch.Size([3, 350]), torch.Size([3, 2]), torch.Size([3]))"},"metadata":{}}]},{"cell_type":"code","source":"class BertForSequenceRegression(nn.Module):\n  \n    def __init__(self, num_marks=2):    \n        super(BertForSequenceRegression, self).__init__()\n        self.num_marks = num_marks        \n        with open(\"/kaggle/working/deberta_model.pkl\", \"rb\") as f:            \n            self.bert = pickle.load(f)\n                \n        self.hidden_1=nn.Linear(2*config.hidden_size, 2*config.hidden_size)\n        self.notline_1=nn.ReLU()\n        self.dropout_1 = nn.Dropout(config.hidden_dropout_prob)\n        self.hidden_2=nn.Linear(2*config.hidden_size, config.hidden_size)\n        self.notline_2=nn.ReLU()\n        self.dropout_2 = nn.Dropout(config.hidden_dropout_prob)\n        self.hidden = nn.Linear(config.hidden_size, 128)\n        self.regres = nn.Linear(128, num_marks)     \n    \n    def forward(self, input_ids, content_vector,\\\n                token_type_ids=None, attention_mask=None, labels=None):\n        output_bert = self.bert(input_ids, token_type_ids, attention_mask).last_hidden_state.mean(1)\n        h_concat=torch.cat((content_vector,output_bert), dim=1)        \n        hidden_vec_1=self.hidden_1(h_concat)\n        hidden_drop_1=self.dropout_1(hidden_vec_1) \n        hidden_vecn_1=self.notline_1(hidden_drop_1) \n        hidden_vec_2=self.hidden_2(hidden_vecn_1)\n        hidden_drop_2=self.dropout_2(hidden_vec_2) \n        hidden_vecn_2=self.notline_2(hidden_drop_2) \n        hidden=self.hidden(hidden_vecn_2)        \n        marks = self.regres(hidden)\n                \n        return marks","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:07.287204Z","iopub.execute_input":"2023-10-05T12:05:07.288012Z","iopub.status.idle":"2023-10-05T12:05:07.295739Z","shell.execute_reply.started":"2023-10-05T12:05:07.287983Z","shell.execute_reply":"2023-10-05T12:05:07.294828Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"config=Namespace(\nhidden_dropout_prob=0.05,\nhidden_size=768\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:07.296923Z","iopub.execute_input":"2023-10-05T12:05:07.297967Z","iopub.status.idle":"2023-10-05T12:05:07.310356Z","shell.execute_reply.started":"2023-10-05T12:05:07.297938Z","shell.execute_reply":"2023-10-05T12:05:07.309539Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model=BertForSequenceRegression()\nmodel","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:07.311483Z","iopub.execute_input":"2023-10-05T12:05:07.312253Z","iopub.status.idle":"2023-10-05T12:05:08.001456Z","shell.execute_reply.started":"2023-10-05T12:05:07.312223Z","shell.execute_reply":"2023-10-05T12:05:08.000537Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"BertForSequenceRegression(\n  (bert): DebertaModel(\n    (embeddings): DebertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n      (LayerNorm): DebertaLayerNorm()\n      (dropout): StableDropout()\n    )\n    (encoder): DebertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaLayer(\n          (attention): DebertaAttention(\n            (self): DisentangledSelfAttention(\n              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n              (pos_dropout): StableDropout()\n              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): StableDropout()\n            )\n            (output): DebertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): DebertaLayerNorm()\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): DebertaLayerNorm()\n            (dropout): StableDropout()\n          )\n        )\n      )\n      (rel_embeddings): Embedding(1024, 768)\n    )\n  )\n  (hidden_1): Linear(in_features=1536, out_features=1536, bias=True)\n  (notline_1): ReLU()\n  (dropout_1): Dropout(p=0.05, inplace=False)\n  (hidden_2): Linear(in_features=1536, out_features=768, bias=True)\n  (notline_2): ReLU()\n  (dropout_2): Dropout(p=0.05, inplace=False)\n  (hidden): Linear(in_features=768, out_features=128, bias=True)\n  (regres): Linear(in_features=128, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error as RMSE","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:08.002973Z","iopub.execute_input":"2023-10-05T12:05:08.003525Z","iopub.status.idle":"2023-10-05T12:05:08.008226Z","shell.execute_reply.started":"2023-10-05T12:05:08.003488Z","shell.execute_reply":"2023-10-05T12:05:08.006997Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"args = Namespace(\n    # Training hyper parameter\n    num_epochs=50,\n    learning_rate=1.2e-5,\n    batch_size=4,\n    seed=99,    \n    cuda=True\n    )","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:08.009718Z","iopub.execute_input":"2023-10-05T12:05:08.010053Z","iopub.status.idle":"2023-10-05T12:05:08.021027Z","shell.execute_reply.started":"2023-10-05T12:05:08.010025Z","shell.execute_reply":"2023-10-05T12:05:08.020119Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def make_train_state(args):\n    return {            \n            'learning_rate': args.learning_rate,\n            'epoch_index': 0,\n            'train_loss': [],\n            'train_acc': [],\n            'val_loss': [],\n            'val_acc': []\n            }","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:08.022414Z","iopub.execute_input":"2023-10-05T12:05:08.023011Z","iopub.status.idle":"2023-10-05T12:05:08.033598Z","shell.execute_reply.started":"2023-10-05T12:05:08.022906Z","shell.execute_reply":"2023-10-05T12:05:08.032657Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"make_train_state(args)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:08.034959Z","iopub.execute_input":"2023-10-05T12:05:08.035407Z","iopub.status.idle":"2023-10-05T12:05:08.051631Z","shell.execute_reply.started":"2023-10-05T12:05:08.035377Z","shell.execute_reply":"2023-10-05T12:05:08.050666Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"{'learning_rate': 1.2e-05,\n 'epoch_index': 0,\n 'train_loss': [],\n 'train_acc': [],\n 'val_loss': [],\n 'val_acc': []}"},"metadata":{}}]},{"cell_type":"code","source":"if not torch.cuda.is_available():\n    args.cuda = False\n\nargs.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n    \nprint(\"Using CUDA: {}\".format(args.cuda))","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:08.053042Z","iopub.execute_input":"2023-10-05T12:05:08.053589Z","iopub.status.idle":"2023-10-05T12:05:08.062958Z","shell.execute_reply.started":"2023-10-05T12:05:08.053559Z","shell.execute_reply":"2023-10-05T12:05:08.062003Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Using CUDA: True\n","output_type":"stream"}]},{"cell_type":"code","source":"train_c.head(1)","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:08.064038Z","iopub.execute_input":"2023-10-05T12:05:08.064897Z","iopub.status.idle":"2023-10-05T12:05:08.120206Z","shell.execute_reply.started":"2023-10-05T12:05:08.064869Z","shell.execute_reply":"2023-10-05T12:05:08.119238Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"     student_id prompt_id                                               text  \\\n0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n\n    content   wording                                   prompt_text_sent  \\\n0  0.205683  0.380538  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   \n\n   len_ratio  \n0   0.098571  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>prompt_text_sent</th>\n      <th>len_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000e8c3c7ddb</td>\n      <td>814d6b</td>\n      <td>The third wave was an experimentto see how peo...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n      <td>0.098571</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import LeaveOneGroupOut\nlogo = LeaveOneGroupOut()","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:08.121464Z","iopub.execute_input":"2023-10-05T12:05:08.121982Z","iopub.status.idle":"2023-10-05T12:05:08.126432Z","shell.execute_reply.started":"2023-10-05T12:05:08.121952Z","shell.execute_reply":"2023-10-05T12:05:08.125506Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"groups = train_c['prompt_id']\nfor i, (train_index, test_index) in enumerate(logo.split(train_c, groups=groups)):    \n    X_train = train_c.iloc[train_index].copy()\n    X_train['split']='train'\n    X_val = train_c.iloc[test_index].copy()\n    X_val['split']='val'\n    X=pd.concat([X_train, X_val], ignore_index=True)\n    print(X[X.split=='train'].prompt_id.value_counts())\n    print(X[X.split=='val'].prompt_id.value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:08.127911Z","iopub.execute_input":"2023-10-05T12:05:08.128510Z","iopub.status.idle":"2023-10-05T12:05:08.172947Z","shell.execute_reply.started":"2023-10-05T12:05:08.128481Z","shell.execute_reply":"2023-10-05T12:05:08.171971Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"prompt_id\n3b9047    2009\nebad26    1996\n814d6b    1103\nName: count, dtype: int64\nprompt_id\n39c16e    2057\nName: count, dtype: int64\nprompt_id\n39c16e    2057\nebad26    1996\n814d6b    1103\nName: count, dtype: int64\nprompt_id\n3b9047    2009\nName: count, dtype: int64\nprompt_id\n39c16e    2057\n3b9047    2009\nebad26    1996\nName: count, dtype: int64\nprompt_id\n814d6b    1103\nName: count, dtype: int64\nprompt_id\n39c16e    2057\n3b9047    2009\n814d6b    1103\nName: count, dtype: int64\nprompt_id\nebad26    1996\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"loss_func = nn.MSELoss()\ngroups = train_c['prompt_id']\nlogo = LeaveOneGroupOut()\n\nfor i, (train_index, test_index) in enumerate(logo.split(train_c, groups=groups)):\n    min_val_loss = np.inf\n    train_state = make_train_state(args)\n    X_train = train_c.iloc[train_index].copy()\n    X_train['split']='train'\n    X_val = train_c.iloc[test_index].copy()\n    X_val['split']='val'\n    X=pd.concat([X_train, X_val], ignore_index=True)\n    \n    data=TextDataset(X, 260)      \n    \n            \n    running_loss = 0.0\n    running_acc = 0.0\n    patience = 0\n    \n    #regr = BertForSequenceRegression().to(args.device)\n    regr = BertForSequenceRegression().to(args.device)\n    \n    lrlast = .001\n    lrmain = args.learning_rate\n    optimizer = optim.Adam(\n    [\n        {\"params\":regr.bert.parameters(),\"lr\": lrmain},\n        {\"params\":regr.regres.parameters(), \"lr\": lrlast},\n       \n   ])  \n    \n    \n    print(f'-------------------- Fold {i+1} --------------------')\n    for epoch in range(args.num_epochs):\n        regr.train()\n        data.set_split('train')\n        batch_generator = generate_batches(data, \n                                           batch_size=args.batch_size, \n                                           device=args.device)\n    \n        running_loss = 0.0\n        running_acc = 0.0\n        for batch_index, batch_dict in enumerate(batch_generator):\n            n_batch=batch_index\n            # the training routine is these 5 steps:\n\n            # --------------------------------------    \n            # step 1. zero the gradients\n                        \n            optimizer.zero_grad()\n\n            # step 2. compute the output\n            y_pred = regr(batch_dict['x_data'], batch_dict['content_vector'], \\\n                          attention_mask=batch_dict['attention_mask'])\n                        \n            # step 3. compute the loss\n            \n            loss = loss_func(y_pred, batch_dict['y_target'].float())\n    \n            #running_loss += (loss.item() - running_loss) / (batch_index + 1)\n            running_loss += loss.item()\n\n            # step 4. use loss to produce gradients\n            loss.backward()\n\n            # step 5. use optimizer to take gradient step\n            optimizer.step()\n            # -----------------------------------------\n            # compute the RMSE\n            acc_t = RMSE(batch_dict['y_target'].to('cpu').numpy(), y_pred.detach().to('cpu').numpy(), squared=False)\n            #running_acc += (acc_t - running_acc) / (batch_index + 1)\n            running_acc += acc_t\n            \n        avg_loss=running_loss/(n_batch+1)\n        \n        train_state['train_loss'].append(running_loss/(n_batch+1))\n        train_state['train_acc'].append(running_acc/(n_batch+1))\n        \n        # Validation loop\n        data.set_split('val')\n        batch_generator = generate_batches(data, \n                                           batch_size=args.batch_size, \n                                           device=args.device)\n        running_loss = 0.\n        running_acc = 0.\n        regr.eval()\n\n        for batch_index, batch_dict in enumerate(batch_generator):\n            n_batch=batch_index\n            # compute the output\n            y_pred = regr(batch_dict['x_data'], batch_dict['content_vector'],\\\n                          attention_mask=batch_dict['attention_mask'])\n                        \n            # step 3. compute the loss\n            loss = loss_func(y_pred, batch_dict['y_target'].float())            \n            #running_loss += (loss.item() - running_loss) / (batch_index + 1)\n            running_loss += loss.item()\n            # compute the accuracy\n            acc_t = RMSE(batch_dict['y_target'].to('cpu').numpy(), y_pred.detach().to('cpu').numpy(), squared=False)\n            #running_acc += (acc_t - running_acc) / (batch_index + 1)\n            running_acc += acc_t\n            \n        avg_acc = running_acc/(n_batch+1) \n        avg_val_loss = running_loss/(n_batch+1)\n        \n        train_state['val_loss'].append(running_loss/(n_batch+1))\n        train_state['val_acc'].append(running_acc/(n_batch+1))\n        \n        print(f'Epoch {epoch+1} Loss: {avg_loss:.3f} SCORE:{avg_acc:.3}')\n\n        #if (avg_val_loss < min_val_loss) and (epoch!=0):\n        if (avg_val_loss < min_val_loss):\n            patience = 0\n            min_val_loss = avg_val_loss\n            model_name='deb_model' +'_'+ str(i)+'.pt'\n            torch.save(regr.state_dict(), model_name)\n            print(f'saving model with score: {avg_acc:.3f}')\n\n        patience += 1    \n        if patience >=3 :\n            print(f'Early Stopping trigerred on epoch: {epoch+1}')            \n            break\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-10-05T12:05:08.174317Z","iopub.execute_input":"2023-10-05T12:05:08.174816Z","iopub.status.idle":"2023-10-05T13:45:43.403406Z","shell.execute_reply.started":"2023-10-05T12:05:08.174787Z","shell.execute_reply":"2023-10-05T13:45:43.402471Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n","output_type":"stream"},{"name":"stdout","text":"-------------------- Fold 1 --------------------\nEpoch 1 Loss: 0.434 SCORE:0.488\nsaving model with score: 0.488\nEpoch 2 Loss: 0.281 SCORE:0.483\nsaving model with score: 0.483\nEpoch 3 Loss: 0.232 SCORE:0.528\nEpoch 4 Loss: 0.199 SCORE:0.473\nsaving model with score: 0.473\nEpoch 5 Loss: 0.165 SCORE:0.522\nEpoch 6 Loss: 0.139 SCORE:0.582\nEarly Stopping trigerred on epoch: 6\n-------------------- Fold 2 --------------------\nEpoch 1 Loss: 0.437 SCORE:0.692\nsaving model with score: 0.692\nEpoch 2 Loss: 0.243 SCORE:0.651\nsaving model with score: 0.651\nEpoch 3 Loss: 0.223 SCORE:0.649\nEpoch 4 Loss: 0.172 SCORE:0.645\nEarly Stopping trigerred on epoch: 4\n-------------------- Fold 3 --------------------\nEpoch 1 Loss: 0.363 SCORE:0.669\nsaving model with score: 0.669\nEpoch 2 Loss: 0.245 SCORE:0.713\nEpoch 3 Loss: 0.202 SCORE:0.645\nsaving model with score: 0.645\nEpoch 4 Loss: 0.174 SCORE:0.582\nsaving model with score: 0.582\nEpoch 5 Loss: 0.148 SCORE:0.633\nEpoch 6 Loss: 0.123 SCORE:0.592\nEarly Stopping trigerred on epoch: 6\n-------------------- Fold 4 --------------------\nEpoch 1 Loss: 0.413 SCORE:0.527\nsaving model with score: 0.527\nEpoch 2 Loss: 0.271 SCORE:0.547\nEpoch 3 Loss: 0.224 SCORE:0.507\nsaving model with score: 0.507\nEpoch 4 Loss: 0.184 SCORE:0.519\nEpoch 5 Loss: 0.155 SCORE:0.515\nEarly Stopping trigerred on epoch: 5\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-05T13:45:43.404692Z","iopub.execute_input":"2023-10-05T13:45:43.405046Z","iopub.status.idle":"2023-10-05T13:45:43.411496Z","shell.execute_reply.started":"2023-10-05T13:45:43.405016Z","shell.execute_reply":"2023-10-05T13:45:43.410504Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 2])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}